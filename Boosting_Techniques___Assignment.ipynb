{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Boosting Techniques | Assignment\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "widm8ZR4RQnn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "987c1ccc"
      },
      "source": [
        "Question 1: What is Boosting in Machine Learning? Explain how it improves weak learners.\n",
        "***\n",
        "Ans:- Boosting is an ensemble learning technique that aims to improve the performance of weak learners by combining them into a strong learner. Weak learners are models that perform slightly better than random guessing, such as shallow decision trees.\n",
        "\n",
        "The core idea behind boosting is to sequentially train a series of weak learners, where each subsequent learner focuses on correcting the errors made by the previous ones. This is typically done by assigning higher weights to the data points that were misclassified by the previous learners.\n",
        "\n",
        "Here's how boosting improves weak learners:\n",
        "\n",
        "1. **Sequential Learning:** Unlike bagging (another ensemble technique), boosting trains learners in a sequential manner. This allows each new learner to learn from the mistakes of the previous ones.\n",
        "2. **Focus on Difficult Examples:** By weighting misclassified data points more heavily, boosting forces subsequent learners to pay more attention to the examples that are harder to classify.\n",
        "3. **Reducing Bias and Variance:** Boosting primarily reduces bias by combining multiple weak learners. However, it can also help reduce variance to some extent.\n",
        "4. **Adaptive Weighting:** The weights assigned to the data points are adaptively adjusted based on the performance of the previous learners. This ensures that the boosting process focuses on the most challenging examples.\n",
        "\n",
        "Popular boosting algorithms include AdaBoost, Gradient Boosting, and XGBoost. These algorithms differ in how they weight the data points and combine the weak learners, but the underlying principle of sequential learning and focusing on difficult examples remains the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2a682f9"
      },
      "source": [
        "Question 2: What is the difference between AdaBoost and Gradient Boosting in terms of how models are trained?\n",
        "***\n",
        "Ans:- Both AdaBoost and Gradient Boosting are popular boosting algorithms, but they differ in how they train the weak learners:\n",
        "\n",
        "**AdaBoost (Adaptive Boosting):**\n",
        "\n",
        "*   **Weighting Data Points:** AdaBoost focuses on adjusting the weights of the data points at each iteration. It assigns higher weights to the misclassified data points, forcing the next weak learner to focus on these difficult examples.\n",
        "*   **Updating Model Weights:** AdaBoost updates the weight of each weak learner based on its performance. Better-performing learners are given higher weights in the final ensemble.\n",
        "*   **Loss Function:** AdaBoost typically uses an exponential loss function.\n",
        "\n",
        "**Gradient Boosting:**\n",
        "\n",
        "*   **Boosting Residuals:** Gradient Boosting focuses on boosting the residuals (the errors) of the previous models. Each new weak learner is trained to predict the residuals of the ensemble built so far.\n",
        "*   **Gradient Descent:** Gradient Boosting uses gradient descent to minimize a loss function. It iteratively adds new weak learners that are trained on the negative gradient of the loss function with respect to the current ensemble's predictions.\n",
        "*   **Loss Function:** Gradient Boosting can use various differentiable loss functions, such as mean squared error (for regression) or log loss (for classification)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "899acede"
      },
      "source": [
        "Question 3: How does regularization help in XGBoost?\n",
        "***\n",
        "Ans:- XGBoost ( extreme Gradient Boosting) is a powerful and popular implementation of gradient boosting that incorporates regularization techniques to prevent overfitting and improve generalization performance. Regularization adds a penalty term to the objective function that the model tries to minimize during training. This penalty discourages the model from becoming too complex and fitting the training data too closely, which can lead to poor performance on unseen data.\n",
        "\n",
        "Here's how regularization helps in XGBoost:\n",
        "\n",
        "1.  **Prevents Overfitting:** Regularization limits the complexity of the individual trees and the overall model. This prevents the model from memorizing the training data and helps it generalize better to new, unseen data.\n",
        "2.  **Controls Tree Complexity:** XGBoost offers several regularization parameters that control the complexity of the trees, such as:\n",
        "    *   `gamma` (or `min_split_loss`): Controls the minimum loss reduction required to make a further partition on a leaf node of the tree. A higher `gamma` makes the algorithm more conservative.\n",
        "    *   `max_depth`: Limits the maximum depth of the individual trees.\n",
        "    *   `min_child_weight`: Defines the minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than `min_child_weight`, the building process gives up further partitioning.\n",
        "3.  **L1 and L2 Regularization:** XGBoost supports both L1 (Lasso) and L2 (Ridge) regularization on the weights of the leaves.\n",
        "    *   **L1 regularization (`reg_alpha`):** Encourages sparsity in the leaf weights, effectively performing feature selection by pushing some weights to zero.\n",
        "    *   **L2 regularization (`reg_lambda`):** Shrinks the leaf weights towards zero, reducing their impact and making the model less sensitive to individual data points.\n",
        "4.  **Reduces Variance:** By limiting the complexity of the model, regularization helps reduce the variance of the predictions, making the model more stable and less prone to fluctuations due to small changes in the training data.\n",
        "5.  **Improves Generalization:** Ultimately, regularization helps XGBoost build models that generalize well to unseen data, leading to better performance on real-world problems."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Why is CatBoost considered efficient for handling categorical data?\n"
      ],
      "metadata": {
        "id": "6QdddSScTfFx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8cba428"
      },
      "source": [
        "Question 4: Why is CatBoost considered efficient for handling categorical data?\n",
        "***\n",
        "Ans:- CatBoost is a gradient boosting library that stands out for its efficient and effective handling of categorical features. Traditional gradient boosting algorithms often require one-hot encoding or other preprocessing techniques for categorical variables, which can lead to increased dimensionality and potential issues like the \"curse of dimensionality.\" CatBoost addresses this by implementing innovative techniques specifically designed for categorical data.\n",
        "\n",
        "Here's why CatBoost is considered efficient for handling categorical data:\n",
        "\n",
        "1.  **Ordered Boosting:** CatBoost employs an \"ordered boosting\" scheme, which is a permutation-based approach to handle categorical features. Instead of using the same training data for all trees, it uses different permutations of the data to train each tree. This helps to avoid target leakage, where information from the target variable \"leaks\" into the features during the training process, especially when dealing with categorical features with many unique values.\n",
        "2.  **Oblivious Decision Trees:** CatBoost uses oblivious decision trees, where the same split is applied to all nodes at the same level of the tree. This structure helps to reduce overfitting and makes the model more robust.\n",
        "3.  **Categorical Feature Statistics:** CatBoost calculates statistics on categorical features during training to determine the best splits. It uses various techniques, such as:\n",
        "    *   **Ordered Target Statistics:** This is a key technique where the target mean is calculated for each category based on the ordered permutations of the data. This helps to avoid target leakage and provides a more robust representation of the categorical feature.\n",
        "    *   **One-Hot Encoding (for low cardinality):** For categorical features with a small number of unique values (low cardinality), CatBoost can still use one-hot encoding.\n",
        "4.  **Handling Combinations of Categorical Features:** CatBoost can automatically consider combinations of categorical features to capture more complex interactions in the data. This can improve the model's performance, especially when there are meaningful interactions between different categorical variables.\n",
        "5.  **Reduced Need for Preprocessing:** Due to its built-in handling of categorical features, CatBoost often reduces the need for extensive manual preprocessing, saving time and effort.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8EbVi9YdTxHb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d7c8e70"
      },
      "source": [
        "Question 5: What are some real-world applications where boosting techniques are\n",
        "preferred over bagging methods?\n",
        "***\n",
        "Ans:- Boosting and bagging are both ensemble learning techniques that combine multiple models to improve predictive performance. However, they differ in their approach and the types of problems for which they are best suited. Boosting techniques are often preferred over bagging methods in certain real-world applications due to their ability to focus on difficult examples and reduce bias.\n",
        "\n",
        "Here are some real-world applications where boosting techniques are often preferred:\n",
        "\n",
        "1.  **Fraud Detection:** Boosting algorithms like XGBoost and LightGBM are widely used in fraud detection systems. They can effectively identify complex patterns and anomalies in large datasets, which is crucial for detecting fraudulent transactions. The ability of boosting to focus on misclassified instances (potential fraudulent activities) makes it particularly effective in this domain.\n",
        "2.  **Credit Risk Assessment:** In finance, boosting models are used to assess credit risk and predict the likelihood of loan defaults. By combining multiple weak learners, boosting can capture intricate relationships between various financial features and predict risk with higher accuracy than individual models or bagging methods.\n",
        "3.  **Customer Churn Prediction:** Boosting techniques are employed in customer relationship management (CRM) to predict customer churn. By analyzing customer behavior and demographics, boosting models can identify customers who are likely to leave and enable businesses to take proactive measures to retain them.\n",
        "4.  **Image and Speech Recognition:** While deep learning has revolutionized image and speech recognition, boosting techniques were historically used and can still be applied in certain scenarios, especially when dealing with smaller datasets or when interpretability is important. Boosting can help improve the accuracy of traditional feature-based methods.\n",
        "5.  **Search Ranking:** Boosting algorithms are used in search engines to rank web pages based on their relevance to a user's query. By combining various ranking signals, boosting can create a robust ranking model that provides accurate and relevant search results.\n",
        "6.  **Medical Diagnosis:** Boosting techniques can be applied in medical diagnosis to predict the likelihood of a disease based on patient data. By combining information from various medical tests and patient history, boosting models can assist doctors in making more accurate diagnoses.\n",
        "7.  **Recommendation Systems:** Boosting can be used in recommendation systems to predict user preferences and recommend relevant items. By analyzing user behavior and item features, boosting models can generate personalized recommendations that improve user engagement."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write a Python program to:\n",
        "* Train an AdaBoost Classifier on the Breast Cancer dataset\n",
        "* Print the model accuracy\n",
        "\n",
        "Datasets:\n",
        "* Use sklearn.datasets.load_breast_cancer() for classification tasks.\n",
        "* Use sklearn.datasets.fetch_california_housing() for regression tasks.\n",
        "***"
      ],
      "metadata": {
        "id": "cPvLaSZKUOvD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "901e8b73",
        "outputId": "aa9f6c45-703e-4bf0-b54c-0cbd04e565dc"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "breast_cancer = load_breast_cancer()\n",
        "X = breast_cancer.data\n",
        "y = breast_cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the AdaBoost Classifier\n",
        "adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "adaboost.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = adaboost.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"AdaBoost Classifier Accuracy: {accuracy:.4f}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Classifier Accuracy: 0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to:\n",
        "* Train a Gradient Boosting Regressor on the California Housing dataset\n",
        "* Evaluate performance using R-squared score\n",
        "***"
      ],
      "metadata": {
        "id": "9SIkM2zgUz4W"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b0ba0b0",
        "outputId": "05f9c070-4f48-4956-ec6b-9a61dd7f019a"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the California Housing dataset\n",
        "california_housing = fetch_california_housing()\n",
        "X = california_housing.data\n",
        "y = california_housing.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Gradient Boosting Regressor\n",
        "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gbr.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = gbr.predict(X_test)\n",
        "\n",
        "# Calculate and print the R-squared score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Gradient Boosting Regressor R-squared Score: {r2:.4f}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor R-squared Score: 0.7756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to:\n",
        "* Train an XGBoost Classifier on the Breast Cancer dataset\n",
        "* Tune the learning rate using GridSearchCV\n",
        "* Print the best parameters and accuracy\n",
        "***"
      ],
      "metadata": {
        "id": "1BJ5fiXnVI_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Define XGBoost Classifier\n",
        "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
        "\n",
        "# Define parameter grid for learning_rate tuning\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3]\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb_clf,\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='accuracy',\n",
        "                           cv=5,\n",
        "                           verbose=1,\n",
        "                           n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate on test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QZlKpMEWFvU",
        "outputId": "5cc1346c-5d60-4bdc-88a8-c7f810e74a41"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [15:42:56] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.1}\n",
            "Test Accuracy: 0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to:\n",
        "* Train a CatBoost Classifier\n",
        "* Plot the confusion matrix using seaborn\n",
        "***"
      ],
      "metadata": {
        "id": "IrkHosAsWVW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define and train CatBoost Classifier\n",
        "model = CatBoostClassifier(verbose=0, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy:\", acc)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot using seaborn\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=data.target_names,\n",
        "            yticklabels=data.target_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix - CatBoost Classifier\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "8rQGFV1lXICJ",
        "outputId": "f81fe015-5b82-4fc5-b676-eb36490c018c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.956140350877193\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: You're working for a FinTech company trying to predict loan default using customer demographics and transaction behavior.\n",
        "\n",
        "The dataset is imbalanced, contains missing values, and has both numeric and\n",
        "categorical features.\n",
        "\n",
        "Describe your step-by-step data science pipeline using boosting techniques:\n",
        "* Data preprocessing & handling missing/categorical values\n",
        "* Choice between AdaBoost, XGBoost, or CatBoost\n",
        "* Hyperparameter tuning strategy\n",
        "* Evaluation metrics you'd choose and why\n",
        "* How the business would benefit from your model\n",
        "***"
      ],
      "metadata": {
        "id": "bVvs3-tTXULw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Data Preprocessing\n",
        "\n",
        "1. **Handle Missing Values**\n",
        "  \n",
        "   * Numeric features: impute using median (robust against outliers).\n",
        "\n",
        "   * Categorical features: impute with most frequent value or add a Missing category.\n",
        "\n",
        "   * If using CatBoost, it can natively handle missing values without imputation.\n",
        "\n",
        "2. **Encoding Categorical Variables**\n",
        "\n",
        "   * One-hot encoding: if using XGBoost or AdaBoost.\n",
        "\n",
        "   * Target encoding / CatBoost encoding: CatBoost directly handles categorical features efficiently.\n",
        "\n",
        "3. **Scaling**\n",
        "\n",
        "   * Not mandatory for boosting, but standardization can help if there are extreme numeric ranges.\n",
        "\n",
        "4. **Dealing with Imbalanced Data**\n",
        "\n",
        "   * Use SMOTE / ADASYN (synthetic oversampling) or undersampling.\n",
        "\n",
        "   * Alternatively, use boosting algorithms with scale_pos_weight (XGBoost) or class_weights (CatBoost).\n",
        "___\n",
        "# Step 2: Choice of Boosting Algorithm\n",
        "\n",
        "* AdaBoost: Simple but less effective for highly imbalanced datasets.\n",
        "\n",
        "* XGBoost: Great for numeric + categorical (after encoding), handles imbalance via scale_pos_weight.\n",
        "\n",
        "* CatBoost : Best choice here because:\n",
        "\n",
        "   * Handles categorical variables directly.\n",
        "\n",
        "   * Handles missing values internally.\n",
        "\n",
        "   * Provides class weights for imbalance.\n",
        "\n",
        "Final choice: CatBoost Classifier.\n",
        "___\n",
        "**Step 3: Hyperparameter Tuning Strategy**\n",
        "\n",
        "Use GridSearchCV or RandomizedSearchCV (faster) with cross-validation (StratifiedKFold).\n",
        "\n",
        "Key parameters to tune:\n",
        "* learning_rate  controls step size (0.010.2 range).\n",
        "* depth  tree depth (410 typical).\n",
        "* iterations  number of boosting rounds (5002000).\n",
        "* l2_leaf_reg  regularization (110).\n",
        "* class_weights  to handle imbalance (e.g., {0:1, 1:5}).\n",
        "\n",
        "Use Bayesian Optimization (Optuna, Hyperopt) for more efficient tuning in production.\n",
        "___\n",
        "**Step 4: Evaluation Metrics**\n",
        "\n",
        "Since the dataset is imbalanced, accuracy is misleading. Prefer:\n",
        "* AUC-ROC  ability to rank defaults higher than non-defaults.\n",
        "* Precision, Recall, F1-score  especially recall (catching defaulters is critical).\n",
        "* Confusion Matrix  to see trade-off between false positives & false negatives.\n",
        "* PR AUC (Precision-Recall curve)  more informative than ROC when dataset is highly imbalanced.\n",
        "\n",
        "Primary Metric: Recall or F1-score (depending on business priority).\n",
        "___\n",
        "**Step 5: Business Benefits**\n",
        "1. Better Risk Management  Identifying high-risk applicants reduces loan defaults.\n",
        "2. Profitability  Approving more reliable borrowers increases repayment rates.\n",
        "3. Customer Segmentation  Helps design personalized interest rates and repayment plans.\n",
        "4. Regulatory Compliance  Transparent and data-driven loan approval improves trust.\n",
        "5. Scalability  Model can be deployed in real-time credit scoring systems."
      ],
      "metadata": {
        "id": "z57oobWiZ6D_"
      }
    }
  ]
}